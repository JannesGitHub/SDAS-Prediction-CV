{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c153454-4318-4475-a34d-efd3b12babe1",
   "metadata": {},
   "source": [
    "# Evaluation of NN-Models and hybrid Algorithm for predicting SDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cad672-8b42-4356-b840-d5953bc8b47e",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b9b630-953a-457d-95b0-20658d3a412b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.9/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from opencv-python) (1.26.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e41a01-ab79-4b7f-af26-4dcd7eb27e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: cellpose 4.0.2\n",
      "Uninstalling cellpose-4.0.2:\n",
      "  Successfully uninstalled cellpose-4.0.2\n",
      "Collecting cellpose\n",
      "  Using cached cellpose-4.0.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.9/site-packages (from cellpose) (1.26.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from cellpose) (1.13.1)\n",
      "Requirement already satisfied: natsort in /opt/conda/lib/python3.9/site-packages (from cellpose) (8.4.0)\n",
      "Requirement already satisfied: tifffile in /opt/conda/lib/python3.9/site-packages (from cellpose) (2024.8.30)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from cellpose) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.9/site-packages (from cellpose) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (from cellpose) (0.16.2)\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.9/site-packages (from cellpose) (4.11.0.86)\n",
      "Requirement already satisfied: fastremap in /opt/conda/lib/python3.9/site-packages (from cellpose) (1.16.1)\n",
      "Requirement already satisfied: imagecodecs in /opt/conda/lib/python3.9/site-packages (from cellpose) (2024.12.30)\n",
      "Requirement already satisfied: roifile in /opt/conda/lib/python3.9/site-packages (from cellpose) (2024.9.15)\n",
      "Requirement already satisfied: fill-voids in /opt/conda/lib/python3.9/site-packages (from cellpose) (2.0.8)\n",
      "Requirement already satisfied: segment_anything in /opt/conda/lib/python3.9/site-packages (from cellpose) (1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch>=1.6->cellpose) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.6->cellpose) (4.13.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch>=1.6->cellpose) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.6->cellpose) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6->cellpose) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch>=1.6->cellpose) (2025.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=1.6->cellpose) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.9/site-packages (from sympy->torch>=1.6->cellpose) (1.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from torchvision->cellpose) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision->cellpose) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision->cellpose) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision->cellpose) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision->cellpose) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->torchvision->cellpose) (2025.1.31)\n",
      "Using cached cellpose-4.0.2-py3-none-any.whl (210 kB)\n",
      "Installing collected packages: cellpose\n",
      "Successfully installed cellpose-4.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall cellpose -y\n",
    "!pip install cellpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17d0e429-078e-4edd-a740-5d6a2194c49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v4.0.1! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cellpose import core, utils, io, models, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea57e9a-a97c-451b-bc42-c414837069cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.2\n"
     ]
    }
   ],
   "source": [
    "import importlib.metadata\n",
    "print(importlib.metadata.version('cellpose'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99314baf-471f-4078-b7f7-c540352c4ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 14:12:24.420201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747059144.434773  977704 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747059144.439039  977704 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747059144.453010  977704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747059144.453028  977704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747059144.453030  977704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747059144.453032  977704 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 14:12:24.457145: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# === Standardbibliotheken ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# === Modell laden und evaluieren ===\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# === Metriken ===\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# f√ºr hybrides Verfahren\n",
    "\n",
    "import sys\n",
    "sys.path.append('../notebooks_HYBRID')  # Pfad zur Datei my_utils.py anpassen\n",
    "from my_utils import (\n",
    "    draw_contours_with_alpha,\n",
    "    extract_line_segments,\n",
    "    plot_line_segments_on_image,\n",
    "    plot_line_midpoints_with_angles,\n",
    "    group_line_segments,\n",
    "    group_line_segments_with_KDTree,\n",
    "    print_result_lines_over_img,\n",
    "    calculate_avg_sdas,\n",
    "    getResults,\n",
    "    calculateMetrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6720aedc-221a-4655-b202-2a56b630fc3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `{arg_name}` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/cnn_v1.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m ResNet50_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/ResNet50_v2.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, safe_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m EfficientNetB0_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/EfficientNetB0_v2.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m paper_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/paper_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m Cyto2_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mCellposeModel(gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcyto2\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m#sometimes Cellpose(...) sometimes CellposeModel()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/saving/saving_api.py:189\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    186\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:367\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m     )\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:444\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[0;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    442\u001b[0m     config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 444\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    449\u001b[0m extract_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:433\u001b[0m, in \u001b[0;36m_model_from_config\u001b[0;34m(config_json, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 433\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/models/model.py:587\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[0;32m--> 587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/models/functional.py:557\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 557\u001b[0m     \u001b[43mprocess_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/models/functional.py:524\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    520\u001b[0m     layer \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[1;32m    521\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Operation):\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected object from deserialization, expected a layer or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperation, got a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/saving/serialization_lib.py:718\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    721\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m could not be deserialized properly. Please\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ensure that components that are Python object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m         )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/layers/core/lambda_layer.py:190\u001b[0m, in \u001b[0;36mLambda.from_config\u001b[0;34m(cls, config, custom_objects, safe_mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m fn_config \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(fn_config, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fn_config\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m fn_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__lambda__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m ):\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_for_lambda_deserialization\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     inner_config \u001b[38;5;241m=\u001b[39m fn_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    192\u001b[0m     fn \u001b[38;5;241m=\u001b[39m python_utils\u001b[38;5;241m.\u001b[39mfunc_load(\n\u001b[1;32m    193\u001b[0m         inner_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    194\u001b[0m         defaults\u001b[38;5;241m=\u001b[39minner_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefaults\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    195\u001b[0m         closure\u001b[38;5;241m=\u001b[39minner_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosure\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    196\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/src/layers/core/lambda_layer.py:172\u001b[0m, in \u001b[0;36mLambda._raise_for_lambda_deserialization\u001b[0;34m(arg_name, safe_mode)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_for_lambda_deserialization\u001b[39m(arg_name, safe_mode):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m safe_mode:\n\u001b[0;32m--> 172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `\u001b[39m\u001b[38;5;132;01m{arg_name}\u001b[39;00m\u001b[38;5;124m` of this `Lambda` layer is a Python lambda. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeserializing it is unsafe. If you trust the source of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig artifact, you can override this error \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    176\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby passing `safe_mode=False` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto `from_config()`, or calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.config.enable_unsafe_deserialization().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The `{arg_name}` of this `Lambda` layer is a Python lambda. Deserializing it is unsafe. If you trust the source of the config artifact, you can override this error by passing `safe_mode=False` to `from_config()`, or calling `keras.config.enable_unsafe_deserialization()."
     ]
    }
   ],
   "source": [
    "# Modelle importieren\n",
    "\n",
    "cnn_model = load_model('../models/cnn_v1.keras')\n",
    "\n",
    "ResNet50_model = load_model('../models/ResNet50_v2.keras', safe_mode=False)\n",
    "\n",
    "EfficientNetB0_model = load_model('../models/EfficientNetB0_v2.keras')\n",
    "\n",
    "paper_model = load_model('../models/paper_model.keras')\n",
    "\n",
    "Cyto2_model = models.CellposeModel(gpu=True, model_type='cyto2')  #sometimes Cellpose(...) sometimes CellposeModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf516a8-0480-4e37-92e6-81384dd86756",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parameter f√ºr hybrides Verfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e958c833-1d70-404f-bf9a-e9594d113e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS:\n",
    "\n",
    "# Cellpose Parameters\n",
    "\n",
    "diameter = 85      # is the smallest possible contour diameter\n",
    "\n",
    "# Clustering Parameters\n",
    "\n",
    "MIN_POINTS_PER_LINE = 5                                         # BDG-Norm: minimal number of elements in a line\n",
    "MAX_POINTS_PER_LINE = 15                                        # maxmimum number of elements in a line\n",
    "ANGLE_DIFF_THRESHOLD = 25                                       # maximum angle difference between current line and next line \n",
    "DISTANCE_THRESHOLD = 10                                         # maximum distance between contours of dendrites-structures\n",
    "REGRESSION_DISTANCE_THRESHOLD = 100                             # maximum distance between current regression line and next line \n",
    "MIN_ANGLE_DIFF_REG_P_THRESHOLD = 75                             # minimal angle difference between current regression line and next line \n",
    "MICROMETER_PER_PIXEL = 0.728265817023213"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee93f9e-a793-4335-be75-36b237a872bc",
   "metadata": {},
   "source": [
    "## Evaluation auf allen Test Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea85bce-1332-408d-9e7f-28837ebd1f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dir = r'../data/bmw_test'\n",
    "\n",
    "min_size = 200\n",
    "\n",
    "results = []\n",
    "\n",
    "# for all images in test_dir\n",
    "for idx, img_name in enumerate(os.listdir(test_dir)):\n",
    "    if img_name.endswith('.jpg') or img_name.endswith('.png'):\n",
    "        \n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        height, width = img.shape\n",
    "\n",
    "        # HYBRIDES VERFAHREN:\n",
    "\n",
    "        masks, flows, styles, imgs_dn = Cyto2_model.eval(img, diameter=diameter, channels=[0, 0])\n",
    "        \n",
    "        line_segments = extract_line_segments(masks)\n",
    "        \n",
    "        dendrite_clusters = group_line_segments_with_KDTree(\n",
    "            line_segments, MAX_POINTS_PER_LINE, MAX_ANGLE_DIFF_REG_P_THRESHOLD,\n",
    "            REGRESSION_DISTANCE_THRESHOLD, ANGLE_DIFF_THRESHOLD, DISTANCE_THRESHOLD,\n",
    "            MIN_POINTS_PER_LINE, MICROMETER_PER_PIXEL\n",
    "        )\n",
    "        \n",
    "        HYBRID_SDAS_pred = calculate_avg_sdas(dendrite_clusters)\n",
    "\n",
    "        # NEURONALE NETZE (MIT TILES):\n",
    "        \n",
    "        # Calculate the number of tiles\n",
    "        rows = height // min_size\n",
    "        cols = width // min_size\n",
    "        \n",
    "        # Split the image into tiles\n",
    "        images = []\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                y_start = i * min_size\n",
    "                x_start = j * min_size\n",
    "                y_end = min(y_start + min_size, height)\n",
    "                x_end = min(x_start + min_size, width)\n",
    "                image = img[y_start:y_end, x_start:x_end]\n",
    "                images.append(image)\n",
    "        \n",
    "        # Collect model predictions\n",
    "        CNN_predictions = []\n",
    "        ResNet50_predictions = []\n",
    "        EfficientNetB0_predictions = []\n",
    "        PaperModel_predictions = []\n",
    "        \n",
    "        for image in images:\n",
    "            image = image.astype(np.float16) / 255.0  # normalize to [0, 1]\n",
    "            image_resized = tf.image.resize(image[..., np.newaxis], (200, 200))  # add channel dimension     \n",
    "            \n",
    "            CNN_prediction = CNN_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            CNN_predictions.append(CNN_prediction)\n",
    "            \n",
    "            ResNet50_prediction = ResNet50_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            ResNet50_predictions.append(ResNet50_prediction)\n",
    "            \n",
    "            EfficientNetB0_prediction = EfficientNetB0_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            EfficientNetB0_predictions.append(EfficientNetB0_prediction)\n",
    "\n",
    "            PaperModel_prediction = paper_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            PaperModel_predictions.append(PaperModel_prediction)\n",
    "        \n",
    "        # Calculate the prediction\n",
    "        CNN_S_value_pred = np.median(CNN_predictions) * 100 # * 100, because we normalized the data when we imported it \n",
    "        CNN_SDAS_pred = CNN_S_value_pred * F_value\n",
    "        \n",
    "        ResNet50_S_value_pred = np.median(ResNet50_predictions) * 100 \n",
    "        ResNet50_SDAS_pred = ResNet50_S_value_pred * F_value\n",
    "        \n",
    "        EfficientNetB0_S_value_pred = np.median(PaperModel_predictions) * 100 \n",
    "        PaperModel_SDAS_pred = PaperModel_S_value_pred * F_value\n",
    "\n",
    "        Paper;pdel_S_value_pred = np.median(EfficientNetB0_predictions) * 100 \n",
    "        EfficientNetB0_SDAS_pred = EfficientNetB0_S_value_pred * F_value\n",
    "\n",
    "  \n",
    "        # Extract the actual SDAS value from the filename\n",
    "        try:\n",
    "            SDAS_true = float(img_name.split('_')[1])\n",
    "            \n",
    "            CNN_std_pred = np.std(CNN_predictions) \n",
    "            CNN_error = abs(CNN_S_value_pred - SDAS_true)  \n",
    "            \n",
    "            ResNet50_std_pred = np.std(ResNet50_predictions) \n",
    "            ResNet50_error = abs(ResNet50_S_value_pred - SDAS_true)\n",
    "\n",
    "            EfficientNetB0_std_pred = np.std(EfficientNetB0_predictions) \n",
    "            EfficientNetB0_error = abs(EfficientNetB0_S_value_pred - SDAS_true)  \n",
    "\n",
    "            results.append((SDAS_true, HYBRID_SDAS_pred, CNN_SDAS_pred, CNN_std_pred, CNN_error, ResNet50_SDAS_pred, ResNet50_std_pred, ResNet50_error, EfficientNetB0_SDAS_pred, EfficientNetB0_std_pred, EfficientNetB0_error, PaperModel_SDAS_pred, PaperModel_std_pred, PaperModel_error))\n",
    "        except:\n",
    "            print(f\"Warning: Couldn't extract SDAS-value from '{img_name}'!\")\n",
    "\n",
    "        if idx % 5 == 0:\n",
    "            print(f\"‚è≥ Processed {idx}/{len(os.listdir(test_dir))} images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be39ae53-b615-4d16-8057-bdbdf98c0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hilfsfunktion zur MAPE-Berechnung (mit 0-Division-Schutz)\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / np.clip(y_true, 1e-8, None))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425cc31-cfa4-43ab-a257-0aad7986ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entpacke Werte aus den Resultaten\n",
    "y_true = [row[0] for row in results]\n",
    "\n",
    "y_pred_HYBRID = [row[1] for row in results]\n",
    "y_pred_CNN = [row[2] for row in results]\n",
    "y_pred_ResNet50 = [row[5] for row in results]\n",
    "y_pred_EfficientNetB0 = [row[8] for row in results]\n",
    "y_pred_PaperModel = [row[11] for row in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b449662-fb89-4d94-a157-7bb04083895a",
   "metadata": {},
   "source": [
    "### Metriken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44e1a3-6864-431b-a408-09785d54a3ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Alle Modelle und ihre Vorhersagen\n",
    "models = {\n",
    "    \"HYBRID\": y_pred_HYBRID,\n",
    "    \"CNN\": y_pred_CNN,\n",
    "    \"ResNet50\": y_pred_ResNet50,\n",
    "    \"EfficientNetB0\": y_pred_EfficientNetB0\n",
    "    \"Paper Model\" : y_pred_PaperModel\n",
    "}\n",
    "\n",
    "# Ausgabe der Metriken\n",
    "for name, y_pred in models.items():\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nüîç {name} Modell:\")\n",
    "    print(f\"   MSE:   {mse:.4f}\")\n",
    "    print(f\"   RMSE:  {rmse:.4f}\")\n",
    "    print(f\"   MAE:   {mae:.4f}\")\n",
    "    print(f\"   MAPE:  {mape:.2f}%\")\n",
    "    print(f\"   R¬≤:    {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b42b1-1506-48ea-a113-166075e1eeac",
   "metadata": {},
   "source": [
    "### Abweichung Pred von True SDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a879420-5b3b-450b-ac14-8d09870685eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiere ground truth zu Array (falls noch nicht geschehen)\n",
    "y_true_array = np.array([row[0] for row in results])\n",
    "\n",
    "# Vorhersagen extrahieren\n",
    "preds = {\n",
    "    \"HYBRID\": np.array([row[1] for row in results]),\n",
    "    \"CNN\": np.array([row[2] for row in results]),\n",
    "    \"ResNet50\": np.array([row[5] for row in results]),\n",
    "    \"EfficientNetB0\": np.array([row[8] for row in results]),\n",
    "    \"Paper Model\": np.array([row[11] for row in results]),\n",
    "}\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, (model_name, y_pred_array) in enumerate(preds.items(), start=1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.plot([0, 100], [0, 100], 'r--', label='Ideal')  # Diagonal\n",
    "    plt.scatter(y_true_array, y_pred_array, alpha=0.7)\n",
    "    plt.xlabel(\"Ground Truth SDAS\")\n",
    "    plt.ylabel(\"Predicted SDAS\")\n",
    "    plt.title(f\"{model_name} Model\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Predicted vs. Ground Truth SDAS for All Models\", fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a565e7-e526-4130-908d-a1db3194add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne Pearson Korrelation f√ºr jedes Modell\n",
    "for model_name, y_pred_array in preds.items():\n",
    "    corr, _ = pearsonr(y_true_array, y_pred_array)\n",
    "    print(f\"Pearson correlation for {model_name}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545546ed-6bd5-421a-8809-5334fd5fe9ca",
   "metadata": {},
   "source": [
    "### Zusammenhang von Varianz und Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572225c-9772-46d8-9fa2-83bd6c2f23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten extrahieren\n",
    "model_data = {\n",
    "    \"CNN\": {\n",
    "        \"stds\": [row[3] for row in results],\n",
    "        \"errors\": [row[4] for row in results],\n",
    "    },\n",
    "    \"ResNet50\": {\n",
    "        \"stds\": [row[6] for row in results],\n",
    "        \"errors\": [row[7] for row in results],\n",
    "    },\n",
    "    \"EfficientNetB0\": {\n",
    "        \"stds\": [row[9] for row in results],\n",
    "        \"errors\": [row[10] for row in results],\n",
    "    }\n",
    "\n",
    "    \"Paper Model\": {\n",
    "        \"stds\": [row[12] for row in results],\n",
    "        \"errors\": [row[13] for row in results],\n",
    "    }\n",
    "}\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(18, 5))\n",
    "for i, (model_name, data) in enumerate(model_data.items(), start=1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    plt.scatter(data[\"stds\"], data[\"errors\"], alpha=0.7, edgecolor='k')\n",
    "    plt.xlabel(\"Standard Deviation of Tile Predictions\")\n",
    "    plt.ylabel(\"Prediction Error\")\n",
    "    plt.title(f\"{model_name}: Std vs. Error\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Prediction Variance vs. Prediction Error\", fontsize=16, y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f452fbb3-8e58-4965-b21e-cf2df113f643",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Verarbeitungszeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a2dca-cb4c-45b9-83b5-dc2dced6284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Anzahl der Bilder\n",
    "num_images = len([img_name for img_name in os.listdir(test_dir) if img_name.endswith('.jpg') or img_name.endswith('.png')])\n",
    "\n",
    "# Timer f√ºr jedes Verfahren initialisieren\n",
    "hybrid_time = 0\n",
    "cnn_time = 0\n",
    "resnet50_time = 0\n",
    "efficientnetb0_time = 0\n",
    "paperModel_time = 0\n",
    "\n",
    "# for all images in test_dir\n",
    "for idx, img_name in enumerate(os.listdir(test_dir)):\n",
    "    if img_name.endswith('.jpg') or img_name.endswith('.png'):\n",
    "        \n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        height, width = img.shape\n",
    "\n",
    "        # HYBRIDES VERFAHREN:\n",
    "        hybrid_start_time = time.time()  # Startzeit f√ºr das hybride Verfahren\n",
    "        masks, flows, styles, imgs_dn = Cyto2_model.eval(img, diameter=diameter, channels=[0, 0])\n",
    "        line_segments = extract_line_segments(masks)\n",
    "        dendrite_clusters = group_line_segments_with_KDTree(\n",
    "            line_segments, MAX_POINTS_PER_LINE, MAX_ANGLE_DIFF_REG_P_THRESHOLD,\n",
    "            REGRESSION_DISTANCE_THRESHOLD, ANGLE_DIFF_THRESHOLD, DISTANCE_THRESHOLD,\n",
    "            MIN_POINTS_PER_LINE, MICROMETER_PER_PIXEL\n",
    "        )\n",
    "        HYBRID_SDAS_pred = calculate_avg_sdas(dendrite_clusters)\n",
    "        hybrid_time += time.time() - hybrid_start_time  # Addiere Zeit f√ºr das hybride Verfahren\n",
    "\n",
    "        # NEURONALE NETZE (MIT TILES):\n",
    "        \n",
    "        cnn_start_time = time.time()  # Startzeit f√ºr das CNN\n",
    "        CNN_predictions = []\n",
    "        for image in images:\n",
    "            image = image.astype(np.float16) / 255.0  # normalize to [0, 1]\n",
    "            image_resized = tf.image.resize(image[..., np.newaxis], (200, 200))  # add channel dimension     \n",
    "            CNN_prediction = CNN_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            CNN_predictions.append(CNN_prediction)\n",
    "        cnn_time += time.time() - cnn_start_time  # Addiere Zeit f√ºr das CNN\n",
    "\n",
    "        resnet50_start_time = time.time()  # Startzeit f√ºr ResNet50\n",
    "        ResNet50_predictions = []\n",
    "        for image in images:\n",
    "            image = image.astype(np.float16) / 255.0\n",
    "            image_resized = tf.image.resize(image[..., np.newaxis], (200, 200))\n",
    "            ResNet50_prediction = ResNet50_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            ResNet50_predictions.append(ResNet50_prediction)\n",
    "        resnet50_time += time.time() - resnet50_start_time  # Addiere Zeit f√ºr ResNet50\n",
    "\n",
    "        efficientnetb0_start_time = time.time()  # Startzeit f√ºr EfficientNetB0\n",
    "        EfficientNetB0_predictions = []\n",
    "        for image in images:\n",
    "            image = image.astype(np.float16) / 255.0\n",
    "            image_resized = tf.image.resize(image[..., np.newaxis], (200, 200))\n",
    "            EfficientNetB0_prediction = EfficientNetB0_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            EfficientNetB0_predictions.append(EfficientNetB0_prediction)\n",
    "        efficientnetb0_time += time.time() - efficientnetb0_start_time  # Addiere Zeit f√ºr EfficientNetB0\n",
    "\n",
    "        paperModel_time_start_time = time.time()  # Startzeit f√ºr EfficientNetB0\n",
    "        paperModel_predictions = []\n",
    "        for image in images:\n",
    "            image = image.astype(np.float16) / 255.0\n",
    "            image_resized = tf.image.resize(image[..., np.newaxis], (200, 200))\n",
    "            paperModel_prediction = paper_model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            paperModel_predictions.append(paperModel_prediction)\n",
    "        paperModel_time += time.time() - paperModel_time_start_time  # Addiere Zeit f√ºr EfficientNetB0\n",
    "\n",
    "        if idx % 5 == 0:\n",
    "            print(f\"‚è≥ Processed {idx}/{len(os.listdir(test_dir))} images...\")\n",
    "\n",
    "# Berechnung der durchschnittlichen Verarbeitungszeit pro Bild\n",
    "hybrid_avg_time = hybrid_time / num_images\n",
    "cnn_avg_time = cnn_time / num_images\n",
    "resnet50_avg_time = resnet50_time / num_images\n",
    "efficientnetb0_avg_time = efficientnetb0_time / num_images\n",
    "paperModel_avg_time = paperModel_time / num_images\n",
    "\n",
    "print(f\"Durchschnittliche Verarbeitungszeit pro Bild:\")\n",
    "print(f\"HYBRID-Verfahren: {hybrid_avg_time:.4f} Sekunden\")\n",
    "print(f\"CNN-Modell: {cnn_avg_time:.4f} Sekunden\")\n",
    "print(f\"ResNet50-Modell: {resnet50_avg_time:.4f} Sekunden\")\n",
    "print(f\"EfficientNetB0-Modell: {efficientnetb0_avg_time:.4f} Sekunden\")\n",
    "print(f\"Paper-Modell: {paperModel_avg_time:.4f} Sekunden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c032c00-24c1-402c-a289-af6e1aaf1778",
   "metadata": {},
   "source": [
    "## Test auf einzelnen Bildern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93446057-49d9-4c74-b7f6-7cb391b6517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = 'AC_39_B9.jpg'  # Replace with the image you want to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d9994-9398-410a-8df1-e7f520e3a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(test_dir, img_name, model):\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    height, width = img.shape\n",
    "    \n",
    "    # Calculate the number of tiles\n",
    "    rows = height // min_size\n",
    "    cols = width // min_size\n",
    "    \n",
    "    # Split the image into tiles\n",
    "    images = []\n",
    "    predictions = []\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            y_start = i * min_size\n",
    "            x_start = j * min_size\n",
    "            y_end = min(y_start + min_size, height)\n",
    "            x_end = min(x_start + min_size, width)\n",
    "            image = img[y_start:y_end, x_start:x_end]\n",
    "            images.append(image)\n",
    "            \n",
    "            # Normalize and resize the image for prediction\n",
    "            image = image.astype(np.float16) / 255.0  # normalize to [0, 1]\n",
    "            image_resized = tf.image.resize(image[..., np.newaxis], (200, 200))  # Add channel dimension            \n",
    "            prediction = model.predict(np.expand_dims(image_resized, axis=0), verbose=0)[0][0]\n",
    "            predictions.append(prediction * 100 * F_value)\n",
    "    \n",
    "    return img, predictions, rows, cols\n",
    "\n",
    "def plot_heatmap_with_image(img, predictions, rows, cols, min_size):\n",
    "    # Reshape predictions to match the number of tiles\n",
    "    heatmap = np.array(predictions).reshape((rows, cols))\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Display the original image\n",
    "    plt.imshow(img, cmap='gray', extent=[0, img.shape[1], img.shape[0], 0])\n",
    "    \n",
    "    # Overlay the heatmap on top of the image\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.5, extent=[0, img.shape[1], img.shape[0], 0])\n",
    "    \n",
    "    # Add color bar (legend for the heatmap)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label('SDAS Prediction')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.title(\"Image with SDAS Heatmap Overlay\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6603635-97a7-46b3-b3cf-5899b33e4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "\n",
    "img, predictions, rows, cols = process_image(test_dir, img_name, CNN_model)\n",
    "\n",
    "print(np.median(predictions))\n",
    "\n",
    "plot_heatmap_with_image(img, predictions, rows, cols, min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd87820-4cad-4b04-89f4-cd282268d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 model\n",
    "\n",
    "img, predictions, rows, cols = process_image(test_dir, img_name, ResNet50_model)\n",
    "\n",
    "print(np.median(predictions))\n",
    "\n",
    "plot_heatmap_with_image(img, predictions, rows, cols, min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f12e7-fe39-4f1b-ba9d-c0b52edaf526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNetB0 model\n",
    "\n",
    "img, predictions, rows, cols = process_image(test_dir, img_name, EfficientNetB0_model)\n",
    "\n",
    "print(np.median(predictions))\n",
    "\n",
    "plot_heatmap_with_image(img, predictions, rows, cols, min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf6fa3-ce8e-4eae-869b-993c2dadbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN with paper weights\n",
    "\n",
    "img, predictions, rows, cols = process_image(test_dir, img_name, paper_model)\n",
    "\n",
    "print(np.median(predictions))\n",
    "\n",
    "plot_heatmap_with_image(img, predictions, rows, cols, min_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19de5fb3-f4de-4ab5-85fe-214f82d6ef82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYBRID model\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "masks, flows, styles, imgs_dn = model.eval(img, diameter=diameter, channels= [0,0]) # Diameter ist entscheidend f√ºr sinnvolle Umrandunungen! -> kleinst m√∂glicher Durchmesser der f√ºllenden Linie\n",
    "\n",
    "img_contours = draw_contours_with_alpha(img, masks, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72b653-a2cf-429e-800b-6eeebe811179",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_segments = extract_line_segments(masks)\n",
    "img_lines = plot_line_segments_on_image(img, line_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3be84-4dfa-4b9b-a8ed-fb58d5b2c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_midpoints_with_angles(line_segments, img_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b109f8-bf85-4ed7-8e7f-5823db517938",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = group_line_segments_with_KDTree(line_segments, MAX_POINTS_PER_LINE, MIN_ANGLE_DIFF_REG_P_THRESHOLD,\n",
    "                         REGRESSION_DISTANCE_THRESHOLD, ANGLE_DIFF_THRESHOLD, DISTANCE_THRESHOLD,\n",
    "                         MIN_POINTS_PER_LINE, MICROMETER_PER_PIXEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fd9abb-e475-4d82-8485-ebfb922fbe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result_lines_over_img(lines, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed74a25-97d0-42c3-9e71-d14dd1d76520",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result_lines_over_img(lines, img_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe5046-8409-49c2-98d7-03e3a1edcabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result_lines_over_img(lines, img_contours)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
